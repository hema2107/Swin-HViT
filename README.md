Swin-HViT: A Hybrid Transformer Approach for Accurate Early-Stage Crop Disease Diagnosis

Agriculture plays a pivotal role in global economic growth, yet it faces significant challenges from pests and crop diseases. 
Early detection is crucial for preventing large-scale crop losses and ensuring food security. 
This study introduces a hybrid transformer model, Swin-HViT, which integrates the strengths of Vision Transformer (ViT) and Swin Transformer to accurately predict crop diseases. 
While ViT captures global image features, Swin Transformer excels at extracting fine-grained local details. 
Evaluated on two benchmark datasets, Corn and PlantDoc, our model achieved accuracies of 98.81% and 81.81%, respectively, surpassing recent works. 
Here, we demonstrate the effectiveness of combining complementary transformer architectures to enhance disease identification in diverse agricultural settings.

The dataset used in this research can be downloaded from the following links:                                                                                                    
Corn Dataset: https://www.kaggle.com/datasets/smaranjitghose/corn-or-maize-leaf-disease-dataset                                                                                  
PlantDoc Dataset: https://www.kaggle.com/datasets/abdulhasibuddin/plant-doc-dataset

The proposed Hybrid Architecture is given below:
<img width="940" height="644" alt="image" src="https://github.com/user-attachments/assets/f4faa9c6-ceee-4fed-9571-0473771e1bd0" />

The Python file Hybrid Swin-ViT model.ipynb contains the necessary code for constructing and evaluating the hybrid model.  

The results are given below:
<img width="944" height="976" alt="image" src="https://github.com/user-attachments/assets/e3efcb03-1353-4982-907d-261d82ba638e" />

